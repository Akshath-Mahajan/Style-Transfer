{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8afd07ba-75f7-4151-8add-f2b8a49942aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Loss fn in BYOL paper\n",
    "def loss_fn(x, y):\n",
    "    x = F.normalize(x, dim=-1, p=2)\n",
    "    y = F.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29fcb7b0-c836-48a3-9ca7-50d99a39b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_path = './improved-net-2.pt'\n",
    "learner_path = './learner-net-2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f4f0b97-03d7-40ac-baa7-99e3301dd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbc93e6-7056-4400-93b9-5d453d0af5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(val, def_val):\n",
    "    return def_val if val is None else val\n",
    "\n",
    "def flatten(t):\n",
    "    return t.reshape(t.shape[0], -1)\n",
    "\n",
    "def singleton(cache_key):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            instance = getattr(self, cache_key)\n",
    "            if instance is not None:\n",
    "                return instance\n",
    "\n",
    "            instance = fn(self, *args, **kwargs)\n",
    "            setattr(self, cache_key, instance)\n",
    "            return instance\n",
    "        return wrapper\n",
    "    return inner_fn\n",
    "\n",
    "def get_module_device(module):\n",
    "    return next(module.parameters()).device\n",
    "\n",
    "def set_requires_grad(model, val):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = val\n",
    "\n",
    "def MaybeSyncBatchnorm(is_distributed = None):\n",
    "    is_distributed = default(is_distributed, dist.is_initialized() and dist.get_world_size() > 1)\n",
    "    return nn.SyncBatchNorm if is_distributed else nn.BatchNorm1d\n",
    "\n",
    "# loss fn\n",
    "\n",
    "# augmentation utils\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)\n",
    "\n",
    "# exponential moving average\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
    "\n",
    "# MLP class for projector and predictor\n",
    "\n",
    "def MLP(dim, projection_size, hidden_size=4096, sync_batchnorm=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        MaybeSyncBatchnorm(sync_batchnorm)(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size)\n",
    "    )\n",
    "\n",
    "def SimSiamMLP(dim, projection_size, hidden_size=4096, sync_batchnorm=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size, bias=False),\n",
    "        MaybeSyncBatchnorm(sync_batchnorm)(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, hidden_size, bias=False),\n",
    "        MaybeSyncBatchnorm(sync_batchnorm)(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size, bias=False),\n",
    "        MaybeSyncBatchnorm(sync_batchnorm)(projection_size, affine=False)\n",
    "    )\n",
    "\n",
    "# a wrapper class for the base neural network\n",
    "# will manage the interception of the hidden layer output\n",
    "# and pipe it into the projecter and predictor nets\n",
    "\n",
    "class NetWrapper(nn.Module):\n",
    "    def __init__(self, net, projection_size, projection_hidden_size, layer = -2, use_simsiam_mlp = False, sync_batchnorm = None):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.layer = layer\n",
    "\n",
    "        self.projector = None\n",
    "        self.projection_size = projection_size\n",
    "        self.projection_hidden_size = projection_hidden_size\n",
    "\n",
    "        self.use_simsiam_mlp = use_simsiam_mlp\n",
    "        self.sync_batchnorm = sync_batchnorm\n",
    "\n",
    "        self.hidden = {}\n",
    "        self.hook_registered = False\n",
    "\n",
    "    def _find_layer(self):\n",
    "        if type(self.layer) == str:\n",
    "            modules = dict([*self.net.named_modules()])\n",
    "            return modules.get(self.layer, None)\n",
    "        elif type(self.layer) == int:\n",
    "            children = [*self.net.children()]\n",
    "            return children[self.layer]\n",
    "        return None\n",
    "\n",
    "    def _hook(self, _, input, output):\n",
    "        device = input[0].device\n",
    "        self.hidden[device] = flatten(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        layer = self._find_layer()\n",
    "        assert layer is not None, f'hidden layer ({self.layer}) not found'\n",
    "        handle = layer.register_forward_hook(self._hook)\n",
    "        self.hook_registered = True\n",
    "\n",
    "    @singleton('projector')\n",
    "    def _get_projector(self, hidden):\n",
    "        _, dim = hidden.shape\n",
    "        create_mlp_fn = MLP if not self.use_simsiam_mlp else SimSiamMLP\n",
    "        projector = create_mlp_fn(dim, self.projection_size, self.projection_hidden_size, sync_batchnorm = self.sync_batchnorm)\n",
    "        return projector.to(hidden)\n",
    "\n",
    "    def get_representation(self, x):\n",
    "        if self.layer == -1:\n",
    "            return self.net(x)\n",
    "\n",
    "        if not self.hook_registered:\n",
    "            self._register_hook()\n",
    "\n",
    "        self.hidden.clear()\n",
    "        _ = self.net(x)\n",
    "        hidden = self.hidden[x.device]\n",
    "        self.hidden.clear()\n",
    "\n",
    "        assert hidden is not None, f'hidden layer {self.layer} never emitted an output'\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, return_projection = True):\n",
    "        representation = self.get_representation(x)\n",
    "\n",
    "        if not return_projection:\n",
    "            return representation\n",
    "\n",
    "        projector = self._get_projector(representation)\n",
    "        projection = projector(representation)\n",
    "        return projection, representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba61513-ee5b-45a5-a46d-fe921f9f18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "DEFAULT_AUG = torch.nn.Sequential(\n",
    "            RandomApply(\n",
    "                T.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                p = 0.3\n",
    "            ),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            RandomApply(\n",
    "                T.GaussianBlur((3, 3), (1.0, 2.0)),\n",
    "                p = 0.2\n",
    "            ),\n",
    "            T.RandomResizedCrop((image_size, image_size)),\n",
    "            T.Normalize(\n",
    "                mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "                std=torch.tensor([0.229, 0.224, 0.225])),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acffa26b-f870-44b1-86fb-7f79bfb8e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x1, x2, temperature=0.7):\n",
    "    # Normalize input embeddings\n",
    "    x1_normalized = F.normalize(x1, dim=-1)\n",
    "    x2_normalized = F.normalize(x2, dim=-1)\n",
    "    \n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = torch.matmul(x1_normalized, x2_normalized.T)\n",
    "    \n",
    "    # Calculate logits\n",
    "    logits = similarity_matrix / temperature\n",
    "    \n",
    "    # Calculate diagonal terms for positive samples\n",
    "    diag_terms = torch.diag(logits)\n",
    "    \n",
    "    # Calculate numerator (positive term)\n",
    "    numerator = torch.exp(diag_terms / temperature)\n",
    "    \n",
    "    # Calculate denominator (positive and negative terms)\n",
    "    denominator = torch.sum(torch.exp(logits), dim=1) + torch.exp(diag_terms / temperature)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = -torch.mean(torch.log(numerator / denominator))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "373ddf53-d569-496f-a05d-88d6e8aed858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        image_size,\n",
    "        hidden_layer = -2,\n",
    "        projection_size = 256,\n",
    "        projection_hidden_size = 4096,\n",
    "        augment_fn = None,\n",
    "        augment_fn2 = None,\n",
    "        moving_average_decay = 0.99,\n",
    "        use_momentum = True,\n",
    "        sync_batchnorm = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "        # default SimCLR augmentation\n",
    "\n",
    "        DEFAULT_AUG = torch.nn.Sequential(\n",
    "            RandomApply(\n",
    "                T.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                p = 0.3\n",
    "            ),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            RandomApply(\n",
    "                T.GaussianBlur((3, 3), (1.0, 2.0)),\n",
    "                p = 0.2\n",
    "            ),\n",
    "            T.RandomResizedCrop((image_size, image_size)),\n",
    "            T.Normalize(\n",
    "                mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "                std=torch.tensor([0.229, 0.224, 0.225])),\n",
    "        )\n",
    "\n",
    "        self.augment1 = default(augment_fn, DEFAULT_AUG)\n",
    "        self.augment2 = default(augment_fn2, self.augment1)\n",
    "\n",
    "        self.online_encoder = NetWrapper(\n",
    "            net,\n",
    "            projection_size,\n",
    "            projection_hidden_size,\n",
    "            layer = hidden_layer,\n",
    "            use_simsiam_mlp = not use_momentum,\n",
    "            sync_batchnorm = sync_batchnorm\n",
    "        )\n",
    "\n",
    "        self.use_momentum = use_momentum\n",
    "        self.target_encoder = None\n",
    "        self.target_ema_updater = EMA(moving_average_decay)\n",
    "\n",
    "        self.online_predictor = MLP(projection_size, projection_size, projection_hidden_size)\n",
    "\n",
    "        # get device of network and make wrapper same device\n",
    "        device = get_module_device(net)\n",
    "        self.to(device)\n",
    "\n",
    "        # send a mock image tensor to instantiate singleton parameters\n",
    "        self.forward(torch.randn(2, 3, image_size, image_size, device=device))\n",
    "\n",
    "    @singleton('target_encoder')\n",
    "    def _get_target_encoder(self):\n",
    "        target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        set_requires_grad(target_encoder, False)\n",
    "        return target_encoder\n",
    "\n",
    "    def reset_moving_average(self):\n",
    "        del self.target_encoder\n",
    "        self.target_encoder = None\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        assert self.use_momentum, 'you do not need to update the moving average, since you have turned off momentum for the target encoder'\n",
    "        assert self.target_encoder is not None, 'target encoder has not been created yet'\n",
    "        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        # y,\n",
    "        return_embedding = False,\n",
    "        return_projection = True\n",
    "    ):\n",
    "        assert not (self.training and x.shape[0] == 1), 'you must have greater than 1 sample when training, due to the batchnorm in the projection layer'\n",
    "\n",
    "        if return_embedding:\n",
    "            return self.online_encoder(x, return_projection = return_projection)\n",
    "\n",
    "        image_one, image_two = self.augment1(x), self.augment2(x)\n",
    "        # print(\"Image shapes:\", image_one.shape, image_two.shape)\n",
    "        images = torch.cat((image_one, image_two), dim = 0)\n",
    "        # labels = torch.cat((), dim=0)\n",
    "        # print(images.shape)\n",
    "        online_projections, _ = self.online_encoder(images)\n",
    "        online_predictions = self.online_predictor(online_projections)\n",
    "        # print(\"Online Projections = online_encoder(aug_1 + aug_2) shapes:\", online_projections.shape, _.shape, online_predictions.shape)\n",
    "        online_pred_one, online_pred_two = online_predictions.chunk(2, dim = 0)\n",
    "        # print(\"Pred (chunked) shapes:\", online_pred_one.shape, online_pred_two.shape)\n",
    "        with torch.no_grad():\n",
    "            target_encoder = self._get_target_encoder() if self.use_momentum else self.online_encoder\n",
    "\n",
    "            target_projections, _ = target_encoder(images)\n",
    "            target_projections = target_projections.detach()\n",
    "\n",
    "            target_proj_one, target_proj_two = target_projections.chunk(2, dim = 0)\n",
    "\n",
    "        loss_one = loss_fn(online_pred_one, target_proj_two.detach())\n",
    "        loss_two = loss_fn(online_pred_two, target_proj_one.detach())\n",
    "\n",
    "        loss = loss_one + loss_two\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071103a7-b640-4dcf-a0dd-fc0e8fc1b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "img_path = \"dataset/style/artbench-10-imagefolder-split/\"\n",
    "\n",
    "data_transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=img_path+\"train\", transform=data_transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root=img_path+\"test\", transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60304f5a-3fc4-4694-a975-bc802c65eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dl =  torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl =  torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee67d5f3-d1c7-452c-ac61-e1be27e84385",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "device = 'cuda'\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "learner = BYOL(\n",
    "    resnet,\n",
    "    image_size = 256,\n",
    "    hidden_layer = 'avgpool',\n",
    "    use_momentum=False\n",
    ")\n",
    "\n",
    "opt = torch.optim.Adam(learner.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc284a5e-bab8-49cb-b1df-7d5537966043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.21093463897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "\n",
    "img_path = \"dataset/style/artbench-10-imagefolder-split/\"\n",
    "\n",
    "data_transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root=img_path+\"test\", transform=data_transform)\n",
    "test_dl =  torch.utils.data.DataLoader(dataset=test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_dl, desc=f'Epoch {0}/{0}', leave=False):\n",
    "        images = images.to(device)\n",
    "        loss = learner(images)\n",
    "        print(loss.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88827e8e-6ce8-486f-a4d6-12d16f0d1b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = True\n",
    "resnet.load_state_dict(torch.load(resnet_path))\n",
    "learner.load_state_dict(torch.load(learner_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c2e083-4a40-420a-8179-06a152603871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.525811195373535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_dl, desc=f'Epoch {0}/{0}', leave=False):\n",
    "        images = images.to(device)\n",
    "        loss = learner(images)\n",
    "        print(loss.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "946998e3-f435-415f-85b9-9f17594029bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.959464430809021\n",
      "Mean Cosine Similarity: 0.9797874689102173\n",
      "Mean Cosine Similarity: 0.9797340631484985\n",
      "Mean Cosine Similarity: 0.9797700643539429\n",
      "Mean Cosine Similarity: 0.9392114281654358\n",
      "Mean Cosine Similarity: 0.9796575903892517\n",
      "Mean Cosine Similarity: 0.9797666668891907\n",
      "Mean Cosine Similarity: 0.9646632671356201\n",
      "Mean Cosine Similarity: 0.9797666668891907\n",
      "Mean Cosine Similarity: 0.9797442555427551\n"
     ]
    }
   ],
   "source": [
    "# Similarity between same class embeddings\n",
    "torch.cuda.empty_cache()\n",
    "idxs = [((i//100)*1000 + (i%100) + 5) for i in range(1000)]\n",
    "# idxs = [_ for _ in range(18)]\n",
    "# print(len(idxs))\n",
    "\n",
    "subset_dataset = torch.utils.data.Subset(test_data, idxs)\n",
    "shuffle_dl = torch.utils.data.DataLoader(subset_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in shuffle_dl:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    embeddings = learner(images, return_embedding = True)\n",
    "    \n",
    "    img = embeddings[0][0:1]\n",
    "    embeddings = embeddings[0][1:]\n",
    "    \n",
    "    cos_similarities = F.cosine_similarity(img.expand_as(embeddings), embeddings, dim=1)\n",
    "    mean_cos_similarity = torch.mean(cos_similarities)\n",
    "    \n",
    "    print(\"Mean Cosine Similarity:\", mean_cos_similarity.item())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdbd49a6-0423-4002-a7a4-70d4716bd06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.33603277802467346\n",
      "Mean Cosine Similarity: 0.30012691020965576\n",
      "Mean Cosine Similarity: -0.1853371560573578\n",
      "Mean Cosine Similarity: 0.07703905552625656\n",
      "Mean Cosine Similarity: 0.11345871537923813\n",
      "Mean Cosine Similarity: 0.30472663044929504\n",
      "Mean Cosine Similarity: -0.27860695123672485\n",
      "Mean Cosine Similarity: 0.14890296757221222\n",
      "Mean Cosine Similarity: 0.08156626671552658\n",
      "Mean Cosine Similarity: -0.25515738129615784\n",
      "Mean Cosine Similarity: 0.46345409750938416\n",
      "Mean Cosine Similarity: 0.21496708691120148\n",
      "Mean Cosine Similarity: -0.2696516215801239\n",
      "Mean Cosine Similarity: -0.24149322509765625\n",
      "Mean Cosine Similarity: -0.3686572313308716\n",
      "Mean Cosine Similarity: 0.15797919034957886\n",
      "Mean Cosine Similarity: 0.10038799792528152\n",
      "Mean Cosine Similarity: -0.1328631043434143\n",
      "Mean Cosine Similarity: -0.27926215529441833\n",
      "Mean Cosine Similarity: 0.14929652214050293\n",
      "Mean Cosine Similarity: 0.22925111651420593\n",
      "Mean Cosine Similarity: -0.6491965651512146\n",
      "Mean Cosine Similarity: -0.24906249344348907\n",
      "Mean Cosine Similarity: -0.1923447549343109\n",
      "Mean Cosine Similarity: 0.2977339029312134\n",
      "Mean Cosine Similarity: 0.4285568296909332\n",
      "Mean Cosine Similarity: 0.015533924102783203\n",
      "Mean Cosine Similarity: -0.09931331127882004\n",
      "Mean Cosine Similarity: -0.3117675185203552\n",
      "Mean Cosine Similarity: -0.5550726652145386\n",
      "Mean Cosine Similarity: 0.32130104303359985\n",
      "Mean Cosine Similarity: 0.20030885934829712\n",
      "Mean Cosine Similarity: -0.12276285141706467\n",
      "Mean Cosine Similarity: -0.39071792364120483\n",
      "Mean Cosine Similarity: -0.1993185132741928\n",
      "Mean Cosine Similarity: 0.46827131509780884\n",
      "Mean Cosine Similarity: 0.4277997612953186\n",
      "Mean Cosine Similarity: -0.522750973701477\n",
      "Mean Cosine Similarity: 0.2978145182132721\n",
      "Mean Cosine Similarity: 0.44829532504081726\n",
      "Mean Cosine Similarity: 0.23932968080043793\n",
      "Mean Cosine Similarity: 0.3205977976322174\n",
      "Mean Cosine Similarity: 0.10915449261665344\n",
      "Mean Cosine Similarity: -0.3092907965183258\n",
      "Mean Cosine Similarity: -0.14368772506713867\n",
      "Mean Cosine Similarity: -0.1217365637421608\n",
      "Mean Cosine Similarity: 0.12827588617801666\n",
      "Mean Cosine Similarity: 0.016285737976431847\n",
      "Mean Cosine Similarity: -0.31783327460289\n",
      "Mean Cosine Similarity: -0.2531913220882416\n",
      "Mean Cosine Similarity: 0.0011481709079816937\n",
      "Mean Cosine Similarity: -0.2520237863063812\n",
      "Mean Cosine Similarity: -0.1887485384941101\n",
      "Mean Cosine Similarity: 0.3677181005477905\n",
      "Mean Cosine Similarity: 0.08086332678794861\n",
      "Mean Cosine Similarity: 0.10860758274793625\n",
      "Mean Cosine Similarity: 0.38524919748306274\n",
      "Mean Cosine Similarity: 0.4256248474121094\n",
      "Mean Cosine Similarity: 0.24708040058612823\n",
      "Mean Cosine Similarity: 0.2898217737674713\n",
      "Mean Cosine Similarity: -0.24897387623786926\n",
      "Mean Cosine Similarity: -0.40706226229667664\n",
      "Mean Cosine Similarity: 0.20135970413684845\n",
      "Mean Cosine Similarity: -0.05071228742599487\n",
      "Mean Cosine Similarity: 0.05524567887187004\n",
      "Mean Cosine Similarity: 0.12101997435092926\n",
      "Mean Cosine Similarity: -0.32818126678466797\n",
      "Mean Cosine Similarity: -0.1413153111934662\n",
      "Mean Cosine Similarity: 0.5156417489051819\n",
      "Mean Cosine Similarity: -0.09831079095602036\n",
      "Mean Cosine Similarity: 0.1488322913646698\n",
      "Mean Cosine Similarity: 0.05911407247185707\n",
      "Mean Cosine Similarity: -0.22771655023097992\n",
      "Mean Cosine Similarity: -0.0564342737197876\n",
      "Mean Cosine Similarity: 0.26851561665534973\n",
      "Mean Cosine Similarity: 0.3216336965560913\n",
      "Mean Cosine Similarity: -0.14442069828510284\n",
      "Mean Cosine Similarity: 0.1875321865081787\n",
      "Mean Cosine Similarity: 0.4049238860607147\n",
      "Mean Cosine Similarity: -0.27002817392349243\n",
      "Mean Cosine Similarity: 0.15501873195171356\n",
      "Mean Cosine Similarity: 0.3077153265476227\n",
      "Mean Cosine Similarity: -0.08849848806858063\n",
      "Mean Cosine Similarity: 0.5288339257240295\n",
      "Mean Cosine Similarity: -0.10269775986671448\n",
      "Mean Cosine Similarity: 0.4867250621318817\n",
      "Mean Cosine Similarity: -0.08983693271875381\n",
      "Mean Cosine Similarity: 0.3348597288131714\n",
      "Mean Cosine Similarity: -0.1336721032857895\n",
      "Mean Cosine Similarity: 0.10201561450958252\n",
      "Mean Cosine Similarity: 0.05706559494137764\n",
      "Mean Cosine Similarity: 0.3089052736759186\n",
      "Mean Cosine Similarity: 0.26079288125038147\n",
      "Mean Cosine Similarity: -0.018541766330599785\n",
      "Mean Cosine Similarity: -0.3612377941608429\n",
      "Mean Cosine Similarity: -0.32851138710975647\n",
      "Mean Cosine Similarity: 0.27084916830062866\n",
      "Mean Cosine Similarity: 0.23666013777256012\n",
      "Mean Cosine Similarity: -0.13450507819652557\n",
      "Mean Cosine Similarity: 0.014188289642333984\n"
     ]
    }
   ],
   "source": [
    "# Similarity different class embeddings\n",
    "torch.cuda.empty_cache()\n",
    "TEST_CASES = 100\n",
    "true_mean = 0 \n",
    "for __ in range(TEST_CASES):\n",
    "    idxs = [\n",
    "        random.randint(1, 999), \n",
    "        random.randint(1001, 1999), \n",
    "        random.randint(2001, 2999),\n",
    "        random.randint(3001, 3999), \n",
    "        random.randint(4001, 4999),\n",
    "        random.randint(5001, 5999), \n",
    "        random.randint(6001, 6999),\n",
    "        random.randint(7001, 7999), \n",
    "        random.randint(8001, 8999),\n",
    "        random.randint(9001, 9999),\n",
    "    ]\n",
    "\n",
    "    subset_dataset = torch.utils.data.Subset(test_data, idxs)\n",
    "    shuffle_dl = torch.utils.data.DataLoader(subset_dataset, batch_size=len(idxs), shuffle=True)\n",
    "    batch_mean = 0\n",
    "    for images, labels in shuffle_dl:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        embeddings = learner(images, return_embedding = True)\n",
    "        rand = random.randint(0, 9)\n",
    "        img = embeddings[0][rand].reshape(1, -1)\n",
    "        indices = torch.tensor([i for i in range(embeddings[0].size(0)) if i != rand])\n",
    "        \n",
    "        embeddings = embeddings[0][indices]\n",
    "        \n",
    "        cos_similarities = F.cosine_similarity(img.expand_as(embeddings), embeddings, dim=1)\n",
    "        mean_cos_similarity = torch.mean(cos_similarities)\n",
    "        \n",
    "        print(\"Mean Cosine Similarity:\", mean_cos_similarity.item())\n",
    "        # break\n",
    "        batch_mean += (mean_cos_similarity.item()**2)**0.5\n",
    "    true_mean += batch_mean/len(shuffle_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "411786d8-4abb-4e39-a7bc-59bc32559083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23770515604992398"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mean / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca97b576-c38b-451b-be64-ba30ba596db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.9797444939613342\n"
     ]
    }
   ],
   "source": [
    "# Similarity in a random batch\n",
    "torch.cuda.empty_cache()\n",
    "shuffle_dl = torch.utils.data.DataLoader(dataset=test_data, batch_size=100, shuffle=True)\n",
    "\n",
    "for images, labels in shuffle_dl:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    embeddings = learner(images, return_embedding = True)\n",
    "    \n",
    "    img = embeddings[0][0:1]\n",
    "    embeddings = embeddings[0][1:]\n",
    "    \n",
    "    cos_similarities = F.cosine_similarity(img.expand_as(embeddings), embeddings, dim=1)\n",
    "    \n",
    "    mean_cos_similarity = torch.mean(cos_similarities)\n",
    "    \n",
    "    print(\"Mean Cosine Similarity:\", mean_cos_similarity.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe67a3e-e6d2-48f9-a793-b5f052f306d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d57e81-5e6b-4332-a045-8420617dee29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf851b-d373-4e27-853f-81eb1b9d002d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c6be4-c66b-4467-808d-f37214543ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dcc6f-0d04-4311-81cd-20725433d392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
